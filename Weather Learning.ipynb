{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire fire_data.txt (35, 256, 512, 1)\n",
      "frac frac_data.txt (35, 256, 512, 1)\n",
      "land ./land_data.txt (35, 256, 512, 1)\n",
      "moisture ./mois_data.txt (35, 256, 512, 1)\n",
      "ndvi ./ndvi_data.txt (35, 256, 512, 1)\n",
      "longwave_energy ./olwr_data.txt (35, 256, 512, 1)\n",
      "(35, 256, 512, 6)\n",
      "(35, 256, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "# The inputs and outptus are the maps downloaded from https://www.nnvl.noaa.gov/view/globaldata.html\n",
    "# The inputs to the model are Land Surface Temperature, Moisture and Longwave Energy. \n",
    "# The output is the average precipitation map. \n",
    "# All maps are in the average weekly format. The idea is to find correlation between the input maps and \n",
    "# the output. \n",
    "\n",
    "input_labels = ['fire', 'frac', 'land', 'moisture', 'ndvi', 'longwave_energy'];\n",
    "files = ['fire_data.txt', 'frac_data.txt', './land_data.txt', './mois_data.txt', './ndvi_data.txt', './olwr_data.txt']\n",
    "input_dict = {}\n",
    "\n",
    "xdim = 256\n",
    "ydim = 512\n",
    "in_chan = 6\n",
    "out_chan = 1\n",
    "\n",
    "# Process the input : input_metrics will contain a 2048 x 4096 image with 9 channels (corresponding to 3 inputs)\n",
    "\n",
    "for label, path in zip(input_labels, files):\n",
    "    \n",
    "    input_dict[label] = [];\n",
    "    input_dict[label] = (np.loadtxt(path,delimiter=',').reshape(-1,xdim,ydim,1))[:35,:,:,:]\n",
    "    print(label, path,input_dict[label].shape)\n",
    "\n",
    "input_metrics = input_dict[input_labels[0]];\n",
    "for label in (input_labels[1:]):\n",
    "    input_metrics = np.concatenate((input_metrics, input_dict[label]), axis=3);\n",
    "\n",
    "# Process the output : output_metric will contain a 256 x 4096 image with 3 channels\n",
    "path = './rain_data.txt'\n",
    "output_metric = (np.loadtxt(path, delimiter=',').reshape(-1,xdim,ydim,1)[:35,:,:,:])\n",
    "output_metric = np.array(output_metric);\n",
    "samples = input_metrics.shape[0];\n",
    "\n",
    "print(input_metrics.shape)\n",
    "print(output_metric.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to obtain the next batch based on the input size and the batch size\n",
    "def next_batch(indices, i):\n",
    "    \n",
    "    ind0, ind1 = i*batch_size, np.minimum((i+1)*batch_size, samples)\n",
    "            \n",
    "    return input_metrics[indices[ind0:ind1], :, :, :], output_metric[indices[ind0:ind1], :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building a simple CNN model that looks like an auto-encoder. This is the section to change for a new model.\n",
    "\n",
    "def conv_net(x):\n",
    "    \n",
    "    x = tf.reshape(x, shape=[-1, xdim, ydim, in_chan], name='reshape_x');\n",
    "    x = tf.cast(x, tf.float32) \n",
    "    \n",
    "    # Encoder\n",
    "    # Scale down by 2x2. Out Channels = 32\n",
    "    conv1 = tf.nn.relu(tf.contrib.layers.conv2d(x, 32, [8, 8], stride=2, padding='SAME', \n",
    "                                                biases_initializer=tf.zeros_initializer()))\n",
    "    # Scale down by 2x2. Out Channels = 16\n",
    "    conv2 = tf.nn.relu(tf.contrib.layers.conv2d(conv1, 16, [8, 8], stride=2, padding='SAME', \n",
    "                                                biases_initializer=tf.zeros_initializer()))\n",
    "    # Scale down by 2x2. Out Channels = 8\n",
    "    conv3 = tf.nn.relu(tf.contrib.layers.conv2d(conv2, 8, [8, 8], stride=2, padding='SAME', \n",
    "                                                biases_initializer=tf.zeros_initializer()))\n",
    "    \n",
    "    # Decoder\n",
    "    # Scale up by 2x2. Out Channels = 16\n",
    "    conv4 = tf.nn.relu(tf.contrib.layers.conv2d_transpose(conv3, 16, [8, 8], stride=2, padding='SAME',\n",
    "                                                         biases_initializer=tf.zeros_initializer()))\n",
    "    # Scale up by 2x2. Out Channels = 32\n",
    "    conv5 = tf.nn.relu(tf.contrib.layers.conv2d_transpose(conv4, 32, [8, 8], stride=2, padding='SAME',\n",
    "                                                         biases_initializer=tf.zeros_initializer()))\n",
    "    # Scale up by 2x2. Out Channels = 1\n",
    "    conv6 = tf.nn.relu(tf.contrib.layers.conv2d_transpose(conv5, out_chan, [8, 8], stride=2, padding='SAME',\n",
    "                                                         biases_initializer=tf.zeros_initializer()))\n",
    "    \n",
    "    return conv6;\n",
    "\n",
    "Y = tf.placeholder(tf.float32, shape=(None,xdim,ydim,out_chan));\n",
    "X = tf.placeholder(tf.float32, shape=[None,xdim,ydim,in_chan]);\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001);\n",
    "\n",
    "out = conv_net(X);\n",
    "loss_op = tf.reduce_sum(tf.multiply(Y-out,Y-out));\n",
    "train_op = optimizer.minimize(loss_op);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0 2257189376.0\n",
      "1 2218280345.6\n",
      "2 2137776409.6\n",
      "3 2073970662.4\n",
      "4 2032044697.6\n",
      "5 1975707392.0\n",
      "6 1939982220.8\n",
      "7 1924345984.0\n",
      "8 1907927168.0\n",
      "9 1899823526.4\n",
      "10 1881510553.6\n",
      "11 1833323264.0\n",
      "12 1788598630.4\n",
      "13 1744103756.8\n",
      "14 1712326169.6\n",
      "15 1681825510.4\n",
      "16 1652552038.4\n",
      "17 1645062304.0\n",
      "18 1620202752.0\n",
      "19 1632557510.4\n",
      "20 1615140787.2\n",
      "21 1606552153.6\n",
      "22 1574707532.8\n",
      "23 1556595072.0\n",
      "24 1570144665.6\n",
      "25 1513407334.4\n",
      "26 1477496064.0\n",
      "27 1432828089.6\n",
      "28 1400380134.4\n",
      "29 1380496806.4\n",
      "30 1238205094.4\n",
      "31 1205282572.8\n",
      "32 1183064454.4\n",
      "33 1187127590.4\n",
      "34 1179688371.2\n",
      "35 1118648646.4\n",
      "36 1101720390.4\n",
      "37 1064130598.4\n",
      "38 1050222137.6\n",
      "39 1045222182.4\n",
      "40 1042751846.4\n",
      "41 1055499430.4\n",
      "42 1033692947.2\n",
      "43 1028391424.0\n",
      "44 1026527782.4\n",
      "45 1046282265.6\n",
      "46 1068994214.4\n",
      "47 1028258009.6\n",
      "48 1020825504.0\n",
      "49 1014691865.6\n",
      "50 1007433280.0\n",
      "51 1006445289.6\n",
      "52 1013859833.6\n",
      "53 1012879065.6\n",
      "54 997363750.4\n",
      "55 993524659.2\n",
      "56 1029183302.4\n",
      "57 1008962598.4\n",
      "58 994964940.8\n",
      "59 989440537.6\n",
      "60 988989644.8\n",
      "61 1010888614.4\n",
      "62 1014126188.8\n",
      "63 1002652860.8\n",
      "64 1002172121.6\n",
      "65 994807513.6\n",
      "66 987117740.8\n",
      "67 983704166.4\n",
      "68 1010724755.2\n",
      "69 1000850892.8\n",
      "70 990419827.2\n",
      "71 989555526.4\n",
      "72 1016369996.8\n",
      "73 982687814.4\n",
      "74 994160512.0\n",
      "75 1027527513.6\n",
      "76 1006655769.6\n",
      "77 992155987.2\n",
      "78 982581126.4\n",
      "79 989606240.0\n",
      "80 995944857.6\n",
      "81 996659072.0\n",
      "82 1005709644.8\n",
      "83 1016886553.6\n",
      "84 1023400812.8\n",
      "85 996989334.4\n",
      "86 987387699.2\n",
      "87 989745088.0\n",
      "88 987994144.0\n",
      "89 988350182.4\n",
      "90 987110617.6\n",
      "91 983307052.8\n",
      "92 991778624.0\n",
      "93 1071624883.2\n",
      "94 990008480.0\n",
      "95 1024973132.8\n",
      "96 977577203.2\n",
      "97 981656403.2\n",
      "98 965192563.2\n",
      "99 967663859.2\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100;\n",
    "batch_size = 8;\n",
    "num_batches = int(np.ceil(float(samples) / batch_size));\n",
    "print(num_batches)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run the initializer\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        indices = np.random.permutation(samples);\n",
    "        \n",
    "        total_loss = 0;\n",
    "        for i in range(num_batches):\n",
    "            x_train, y_train = next_batch(indices, i);\n",
    "            [loss, train] = sess.run([loss_op, train_op], feed_dict={X: x_train, Y: y_train});            \n",
    "            total_loss += loss;\n",
    "        \n",
    "        print(epoch, total_loss / num_batches);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

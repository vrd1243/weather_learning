{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import imageio\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire ./fire_data.txt (89, 168, 512, 1)\n",
      "frac ./frac_data.txt (89, 168, 512, 1)\n",
      "land ./land_data.txt (89, 168, 512, 1)\n",
      "moisture ./mois_data.txt (89, 168, 512, 1)\n",
      "ndvi ./ndvi_data.txt (89, 168, 512, 1)\n",
      "longwave_energy ./olwr_data.txt (89, 168, 512, 1)\n",
      "(89, 168, 512, 6)\n",
      "(89, 168, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "# The inputs and outptus are the maps downloaded from https://www.nnvl.noaa.gov/view/globaldata.html\n",
    "# The inputs to the model are Land Surface Temperature, Moisture and Longwave Energy. \n",
    "# The output is the average precipitation map. \n",
    "# All maps are in the average weekly format. The idea is to find correlation between the input maps and \n",
    "# the output. \n",
    "\n",
    "input_labels = ['fire', 'frac', 'land', 'moisture', 'ndvi', 'longwave_energy'];\n",
    "files = ['./fire_data.txt', './frac_data.txt', './land_data.txt', './mois_data.txt', './ndvi_data.txt', './olwr_data.txt']\n",
    "input_dict = {}\n",
    "\n",
    "#xdim = 256\n",
    "xdim = 168\n",
    "ydim = 512\n",
    "in_chan = 6\n",
    "out_chan = 1\n",
    "\n",
    "# Process the input : input_metrics will contain a 2048 x 4096 image with 9 channels (corresponding to 3 inputs)\n",
    "\n",
    "for label, path in zip(input_labels, files):\n",
    "    \n",
    "    input_dict[label] = [];\n",
    "    input_dict[label] = (np.loadtxt(path,delimiter=',').reshape(-1,xdim,ydim,1))\n",
    "    print(label, path,input_dict[label].shape)\n",
    "\n",
    "input_metrics = input_dict[input_labels[0]];\n",
    "for label in (input_labels[1:]):\n",
    "    input_metrics = np.concatenate((input_metrics, input_dict[label]), axis=3);\n",
    "\n",
    "# Process the output : output_metric will contain a 256 x 4096 image with 3 channels\n",
    "path = './rain_data.txt'\n",
    "output_metric = (np.loadtxt(path, delimiter=',').reshape(-1,xdim,ydim,1))\n",
    "output_metric = np.array(output_metric);\n",
    "\n",
    "print(input_metrics.shape)\n",
    "print(output_metric.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "N_images = -5;\n",
    "\n",
    "input_metrics_test = input_metrics[N_images:,:,:,:];\n",
    "output_metric_test = output_metric[N_images:,:,:,:];\n",
    "\n",
    "input_metrics = input_metrics[:N_images,:,:,:];\n",
    "output_metrics = output_metric[:N_images,:,:,:];\n",
    "\n",
    "samples = input_metrics.shape[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to obtain the next batch based on the input size and the batch size\n",
    "def next_batch(indices, i):\n",
    "    \n",
    "    ind0, ind1 = i*batch_size, np.minimum((i+1)*batch_size, samples)\n",
    "            \n",
    "    return input_metrics[indices[ind0:ind1], :, :, :], output_metric[indices[ind0:ind1], :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building a simple CNN model that looks like an auto-encoder. This is the section to change for a new model.\n",
    "\n",
    "def conv_net(x):\n",
    "    \n",
    "    x = tf.reshape(x, shape=[-1, xdim, ydim, in_chan], name='reshape_x');\n",
    "    x = tf.cast(x, tf.float32) \n",
    "    \n",
    "    l2_reg = tf.contrib.layers.l2_regularizer(5.0);\n",
    "    # Encoder\n",
    "    \n",
    "    # Scale down by 2x2. Out Channels = 16\n",
    "    conv1 = tf.nn.relu(tf.contrib.layers.conv2d(conv0, 8, [4, 4], stride=2, padding='SAME', \n",
    "                                                biases_initializer=tf.zeros_initializer(),\n",
    "                                                weights_regularizer=l2_reg));\n",
    "    \n",
    "    \n",
    "    # Scale down by 2x2. Out Channels = 8\n",
    "    conv2 = tf.nn.relu(tf.contrib.layers.conv2d(conv1, 16, [4, 4], stride=2, padding='SAME', \n",
    "                                                biases_initializer=tf.zeros_initializer(),\n",
    "                                                weights_regularizer=l2_reg));\n",
    "    \n",
    "    # Scale down by 2x2. Out Channels = 8\n",
    "    conv3 = tf.nn.relu(tf.contrib.layers.conv2d(conv2, 32, [4, 4], stride=2, padding='SAME', \n",
    "                                                biases_initializer=tf.zeros_initializer(),\n",
    "                                                weights_regularizer=l2_reg));\n",
    "    \n",
    "    # Decoder\n",
    "    # Scale up by 2x2. Out Channels = 16\n",
    "    conv4 = tf.nn.relu(tf.contrib.layers.conv2d_transpose(conv3, 32, [4, 4], stride=2, padding='SAME',\n",
    "                                                          biases_initializer=tf.zeros_initializer(),\n",
    "                                                          weights_regularizer=l2_reg));\n",
    "    \n",
    "    # Scale up by 2x2. Out Channels = 32\n",
    "    conv5 = tf.nn.relu(tf.contrib.layers.conv2d_transpose(conv2, 16, [4, 4], stride=2, padding='SAME',\n",
    "                                                          biases_initializer=tf.zeros_initializer(),\n",
    "                                                          weights_regularizer=l2_reg));\n",
    "    \n",
    "    # Scale up by 2x2. Out Channels = 1\n",
    "    conv6 = tf.nn.relu(tf.contrib.layers.conv2d_transpose(conv5, out_chan, [4, 4], stride=2, padding='SAME',\n",
    "                                                          biases_initializer=tf.zeros_initializer(),\n",
    "                                                          weights_regularizer=l2_reg));\n",
    "    \n",
    "    \n",
    "    return conv6;\n",
    "\n",
    "Y = tf.placeholder(tf.float32, shape=(None,xdim,ydim,out_chan));\n",
    "X = tf.placeholder(tf.float32, shape=[None,xdim,ydim,in_chan]);\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001);\n",
    "\n",
    "out = conv_net(X);\n",
    "loss_op = tf.reduce_sum(tf.multiply(Y-out,Y-out));\n",
    "train_op = optimizer.minimize(loss_op);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load colorbar for rain\n",
    "color_bar = imageio.imread('rain_colorbar.png')\n",
    "color_bar = color_bar[0, :, 0:3].astype(float)\n",
    "\n",
    "c_n = np.shape(color_bar)[0]\n",
    "\n",
    "color_bar_data = np.exp(np.linspace(np.log(1), np.log(375), c_n)).reshape((c_n, 1, 1, 1))\n",
    "color_bar_data = (color_bar_data - 1) / (375 - 1)\n",
    "\n",
    "# Function for reconstructing rain image based on output from network\n",
    "def generate_rainfall_images(rain_data, filename):\n",
    "    ind = np.argmin(abs(color_bar_data - rain_data), axis=0)\n",
    "    \n",
    "    rain_image = np.uint8(color_bar[ind, :].reshape((xdim, ydim, 3)).astype(int))\n",
    "    \n",
    "    imageio.imwrite(filename, rain_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0 83529.40625 83076.8125\n",
      "1 79780.015625 80058.7875\n",
      "2 76976.1132812 77587.875\n",
      "3 74689.028125 75522.6125\n",
      "4 72680.1796875 73595.9375\n",
      "5 70835.0601562 71700.61875\n",
      "6 69013.6496094 69959.0875\n",
      "7 67317.5285156 68218.9375\n",
      "8 65757.1 66723.79375\n",
      "9 64283.1074219 65211.09375\n",
      "10 62866.1464844 63920.6\n",
      "11 61471.0796875 62396.03125\n",
      "12 60097.178125 61062.4125\n",
      "13 58772.1957031 59721.475\n",
      "14 57481.2488281 58393.1375\n",
      "15 56182.9453125 57116.06875\n",
      "16 54920.9054688 55780.44375\n",
      "17 53665.6953125 54584.65625\n",
      "18 52446.2683594 53304.93125\n",
      "19 51279.4480469 52115.528125\n",
      "20 50121.7476563 50964.05\n",
      "21 49000.9628906 49723.309375\n",
      "22 47798.825 48749.8125\n",
      "23 46726.5738281 47735.9375\n",
      "24 45666.2964844 46470.38125\n",
      "25 44583.2070312 45357.409375\n",
      "26 43544.0882812 44311.9375\n",
      "27 42484.834375 43322.83125\n",
      "28 41501.6863281 42317.221875\n",
      "29 40500.3988281 41225.55\n",
      "30 39571.2109375 40299.64375\n",
      "31 38613.7683594 39375.36875\n",
      "32 37693.6042969 38478.125\n",
      "33 36765.8863281 37603.88125\n",
      "34 35847.1931641 36563.86875\n",
      "35 34998.9105469 35800.725\n",
      "36 34143.0566406 34886.846875\n",
      "37 33287.1144531 34090.21875\n",
      "38 32445.4673828 33219.996875\n",
      "39 31663.85625 32345.18125\n",
      "40 30853.7482422 31709.334375\n",
      "41 30071.4900391 30789.71875\n",
      "42 29319.3460937 30115.653125\n",
      "43 28568.9730469 29272.259375\n",
      "44 27826.009375 28555.728125\n",
      "45 27118.1128906 27790.2625\n",
      "46 26397.8189453 27126.94375\n",
      "47 25757.4638672 26460.575\n",
      "48 25072.8837891 25830.953125\n",
      "49 24450.3689453 25104.38125\n",
      "50 23770.6818359 24484.3109375\n",
      "51 23130.7013672 23797.2546875\n",
      "52 22507.3683594 23221.659375\n",
      "53 21908.0058594 22612.9234375\n",
      "54 21333.3853516 22026.871875\n",
      "55 20753.875 21489.415625\n",
      "56 20222.9611328 20892.8171875\n",
      "57 19667.0761719 20348.946875\n",
      "58 19104.7933594 19765.346875\n",
      "59 18584.1358398 19245.3359375\n",
      "60 18087.5095703 18730.040625\n",
      "61 17598.0177734 18321.696875\n",
      "62 17125.98125 17790.2453125\n",
      "63 16639.3994141 17272.334375\n",
      "64 16197.9664062 16841.25\n",
      "65 15734.9655273 16365.04375\n",
      "66 15317.9344727 15935.0953125\n",
      "67 14871.1646484 15510.80625\n",
      "68 14443.3317383 15229.728125\n",
      "69 14130.5162109 14767.1484375\n",
      "70 13688.1938477 14316.828125\n",
      "71 13271.1382812 13878.125\n",
      "72 12869.8205078 13481.1734375\n",
      "73 12492.9599609 13142.7546875\n",
      "74 12160.4397461 12794.9390625\n",
      "75 11806.2197266 12423.1304687\n",
      "76 11453.7042969 12086.5664062\n",
      "77 11121.2855469 11740.259375\n",
      "78 10806.6745117 11451.496875\n",
      "79 10484.5264648 11136.1851562\n",
      "80 10190.7734375 10801.15625\n",
      "81 9892.16113281 10537.878125\n",
      "82 9613.85166016 10238.3414062\n",
      "83 9322.746875 9944.78671875\n",
      "84 9059.13564453 9657.296875\n",
      "85 8791.70820312 9399.16953125\n",
      "86 8536.32231445 9157.7640625\n",
      "87 8288.97661133 8908.825\n",
      "88 8044.39287109 8654.32421875\n",
      "89 7824.9246582 8404.86328125\n",
      "90 7599.82729492 8187.95390625\n",
      "91 7379.36850586 7969.7140625\n",
      "92 7157.1734375 7755.0703125\n",
      "93 6963.71191406 7600.146875\n",
      "94 6774.08383789 7343.33984375\n",
      "95 6560.84746094 7156.70078125\n",
      "96 6373.72480469 6953.421875\n",
      "97 6194.80288086 6773.5140625\n",
      "98 6006.0003418 6621.3265625\n",
      "99 5841.60117187 6423.10976563\n",
      "100 5664.80253906 6273.64101563\n",
      "101 5504.14716797 6089.49023438\n",
      "102 5349.08291016 5941.6203125\n",
      "103 5199.54624023 5809.08476562\n",
      "104 5056.02167969 5622.32734375\n",
      "105 4930.69711914 5498.26210938\n",
      "106 4785.19414062 5360.32382812\n",
      "107 4651.48447266 5256.8484375\n",
      "108 4527.6375 5077.10195313\n",
      "109 4399.82060547 4986.8515625\n",
      "110 4280.39533691 4868.65546875\n",
      "111 4169.64326172 4730.47421875\n",
      "112 4060.41420898 4626.3015625\n",
      "113 3952.71801758 4523.44140625\n",
      "114 3849.1829834 4435.49453125\n",
      "115 3757.54899902 4314.82539063\n",
      "116 3658.02016602 4243.38476562\n",
      "117 3567.76340332 4125.01484375\n",
      "118 3476.45629883 4054.31796875\n",
      "119 3402.753125 3977.51601562\n",
      "120 3320.48642578 3871.60585937\n",
      "121 3244.6980957 3806.62226563\n",
      "122 3165.12949219 3734.8546875\n",
      "123 3085.85588379 3651.890625\n",
      "124 3014.16816406 3590.840625\n",
      "125 2945.95024414 3523.4953125\n",
      "126 2884.53728027 3460.20546875\n",
      "127 2823.83449707 3381.02578125\n",
      "128 2764.99655762 3331.55234375\n",
      "129 2701.23344727 3272.04746094\n",
      "130 2648.72092285 3220.52597656\n",
      "131 2596.3607666 3160.3765625\n",
      "132 2546.89580078 3108.29550781\n",
      "133 2503.16640625 3063.184375\n",
      "134 2448.8845459 3030.93398437\n",
      "135 2409.98796387 2970.12949219\n",
      "136 2370.01330566 2926.09296875\n",
      "137 2323.94396973 2884.71523437\n",
      "138 2288.49970703 2848.6734375\n",
      "139 2251.9602417 2799.41015625\n",
      "140 2209.70533447 2769.77617187\n",
      "141 2177.7086792 2749.94804687\n",
      "142 2147.00855713 2704.57167969\n",
      "143 2118.87373047 2668.04570312\n",
      "144 2088.36149902 2638.93085938\n",
      "145 2057.83562012 2616.63964844\n",
      "146 2031.15006104 2579.28789062\n",
      "147 2010.0564209 2550.58085937\n",
      "148 1986.9939209 2528.1421875\n",
      "149 1954.57543945 2511.42226562\n",
      "150 1933.58394775 2489.16171875\n",
      "151 1911.31544189 2454.59296875\n",
      "152 1891.13220215 2438.58691406\n",
      "153 1870.34458008 2425.6359375\n",
      "154 1850.90686035 2390.93613281\n",
      "155 1834.22282715 2388.11445313\n",
      "156 1818.34249268 2361.26914063\n",
      "157 1801.39521484 2349.51621094\n",
      "158 1786.22254639 2333.23457031\n",
      "159 1772.04798584 2319.44101563\n",
      "160 1761.9460083 2312.05488281\n",
      "161 1751.35372314 2283.42929688\n",
      "162 1740.3638916 2282.16777344\n",
      "163 1723.4744873 2266.31855469\n",
      "164 1709.79359131 2247.57578125\n",
      "165 1696.51531982 2241.99433594\n",
      "166 1688.08204346 2239.62226563\n",
      "167 1679.86938477 2219.75117188\n",
      "168 1670.48430176 2210.54648438\n",
      "169 1662.22944336 2210.35351562\n",
      "170 1657.54414062 2194.56484375\n",
      "171 1647.35307617 2196.59296875\n",
      "172 1637.09588623 2180.34179688\n",
      "173 1632.75328369 2172.07382813\n",
      "174 1626.77805176 2163.42949219\n",
      "175 1623.82591553 2160.3953125\n",
      "176 1615.90488281 2143.74394531\n",
      "177 1609.14498291 2153.45742187\n",
      "178 1604.38912354 2137.59335938\n",
      "179 1598.79141846 2136.1171875\n",
      "180 1592.38164063 2132.51679688\n",
      "181 1588.78554687 2122.14160156\n",
      "182 1586.53383789 2118.42558594\n",
      "183 1580.07142334 2116.77070313\n",
      "184 1577.93035889 2108.34511719\n",
      "185 1574.56723633 2111.09980469\n",
      "186 1570.96713867 2102.52773437\n",
      "187 1569.01751709 2107.0328125\n",
      "188 1564.6637085 2101.66875\n",
      "189 1564.20534668 2092.63417969\n",
      "190 1560.26448975 2096.70820313\n",
      "191 1557.27042236 2096.27929688\n",
      "192 1557.05430908 2084.96386719\n",
      "193 1552.43414307 2088.3875\n",
      "194 1550.02403564 2083.63007813\n",
      "195 1548.18100586 2076.96035156\n",
      "196 1547.90464478 2078.20625\n",
      "197 1545.29069824 2083.6140625\n",
      "198 1548.31403809 2076.43554688\n",
      "199 1543.83028564 2081.4828125\n",
      "200 1543.56414795 2068.61523438\n",
      "201 1541.14077148 2070.15527344\n",
      "202 1541.1760498 2073.7171875\n",
      "203 1538.31403809 2069.76601562\n",
      "204 1536.68675537 2068.84414062\n",
      "205 1536.5026123 2061.06679687\n",
      "206 1536.84818115 2073.21289062\n",
      "207 1536.41976318 2058.66875\n",
      "208 1533.33746338 2061.14609375\n",
      "209 1533.75424805 2064.56523437\n",
      "210 1535.15998535 2061.08417969\n",
      "211 1530.40302734 2056.94277344\n",
      "212 1531.39754639 2058.84726563\n",
      "213 1533.18751221 2062.08671875\n",
      "214 1531.99432373 2056.0265625\n",
      "215 1531.16229248 2060.35507813\n",
      "216 1529.61755371 2048.14003906\n",
      "217 1530.50284424 2059.26679688\n",
      "218 1527.07131348 2053.73378906\n",
      "219 1529.71072998 2062.78769531\n",
      "220 1530.13295898 2051.3375\n",
      "221 1528.84260254 2060.85644531\n",
      "222 1528.04959717 2050.64648438\n",
      "223 1527.0741333 2051.56835938\n",
      "224 1526.32601318 2055.05058594\n",
      "225 1524.53753662 2050.384375\n",
      "226 1524.88139648 2053.87265625\n",
      "227 1525.30009766 2052.10898438\n",
      "228 1526.32539062 2045.35390625\n",
      "229 1523.55330811 2056.93183594\n",
      "230 1524.85101318 2053.81621094\n",
      "231 1524.23204346 2049.43808594\n",
      "232 1523.65212402 2058.88125\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300;\n",
    "batch_size = 8;\n",
    "num_batches = int(np.ceil(float(samples) / batch_size));\n",
    "print(num_batches)\n",
    "\n",
    "loss_arr = [];\n",
    "test_arr = [];\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        indices = np.random.permutation(samples);\n",
    "        \n",
    "        # Compute the loss across all the batches\n",
    "        total_loss = 0;\n",
    "        for i in range(num_batches):\n",
    "            x_train, y_train = next_batch(indices, i);\n",
    "            [loss, train] = sess.run([loss_op, train_op], feed_dict={X: x_train, Y: y_train});            \n",
    "            total_loss += loss;\n",
    "        \n",
    "        loss_arr.append(total_loss / num_batches / batch_size)\n",
    "        \n",
    "        # Test data\n",
    "        x_test = input_metrics_test\n",
    "        y_test = output_metric_test\n",
    "        \n",
    "        [test_acc] = sess.run([loss_op], feed_dict={X: x_test, Y: y_test});\n",
    "        \n",
    "        test_arr.append(test_acc / x_test.shape[0]);\n",
    "        print(epoch, total_loss / num_batches / batch_size, test_acc / x_test.shape[0]);\n",
    "        \n",
    "    save_path = saver.save(sess, \"./model.ckpt\")\n",
    "    \n",
    "    # Make rain plots from network outputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./model.ckpt\")\n",
    "    for i in range(-N_images):\n",
    "        x_test = input_metrics_test[i, :, :, :].reshape((1, xdim, ydim, in_chan))\n",
    "        y_test = output_metric_test[i, :, :, :].reshape((1, xdim, ydim, out_chan))\n",
    "        \n",
    "        [output_data] = sess.run([out], feed_dict={X: x_test, Y: y_test});\n",
    "        \n",
    "        generate_rainfall_images(output_data, 'rainfall' + str(i) + '_generated.png')\n",
    "        generate_rainfall_images(y_test, 'rainfall' + str(i) + '_true.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

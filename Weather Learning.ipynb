{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire ./fire_data.txt (89, 256, 512, 1)\n",
      "frac ./frac_data.txt (89, 256, 512, 1)\n",
      "land ./land_data.txt (89, 256, 512, 1)\n",
      "moisture ./mois_data.txt (89, 256, 512, 1)\n",
      "ndvi ./ndvi_data.txt (89, 256, 512, 1)\n",
      "longwave_energy ./olwr_data.txt (89, 256, 512, 1)\n",
      "(89, 256, 512, 6)\n",
      "(89, 256, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "# The inputs and outptus are the maps downloaded from https://www.nnvl.noaa.gov/view/globaldata.html\n",
    "# The inputs to the model are Land Surface Temperature, Moisture and Longwave Energy. \n",
    "# The output is the average precipitation map. \n",
    "# All maps are in the average weekly format. The idea is to find correlation between the input maps and \n",
    "# the output. \n",
    "\n",
    "input_labels = ['fire', 'frac', 'land', 'moisture', 'ndvi', 'longwave_energy'];\n",
    "files = ['./fire_data.txt', './frac_data.txt', './land_data.txt', './mois_data.txt', './ndvi_data.txt', './olwr_data.txt']\n",
    "input_dict = {}\n",
    "\n",
    "xdim = 256\n",
    "ydim = 512\n",
    "in_chan = 6\n",
    "out_chan = 1\n",
    "\n",
    "# Process the input : input_metrics will contain a 2048 x 4096 image with 9 channels (corresponding to 3 inputs)\n",
    "\n",
    "for label, path in zip(input_labels, files):\n",
    "    \n",
    "    input_dict[label] = [];\n",
    "    input_dict[label] = (np.loadtxt(path,delimiter=',').reshape(-1,xdim,ydim,1))\n",
    "    print(label, path,input_dict[label].shape)\n",
    "\n",
    "input_metrics = input_dict[input_labels[0]];\n",
    "for label in (input_labels[1:]):\n",
    "    input_metrics = np.concatenate((input_metrics, input_dict[label]), axis=3);\n",
    "\n",
    "# Process the output : output_metric will contain a 256 x 4096 image with 3 channels\n",
    "path = './rain_data.txt'\n",
    "output_metric = (np.loadtxt(path, delimiter=',').reshape(-1,xdim,ydim,1))\n",
    "output_metric = np.array(output_metric);\n",
    "samples = input_metrics.shape[0];\n",
    "\n",
    "print(input_metrics.shape)\n",
    "print(output_metric.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data along the images and the inputs for all channels.\n",
    "\n",
    "for i in range(input_metrics.shape[0]):\n",
    "    for c in range(in_chan):\n",
    "        input_metrics[i,:,:,c] = preprocessing.normalize(input_metrics[i,:,:,c])\n",
    "\n",
    "    output_metric[i,:,:,0] = preprocessing.normalize(output_metric[i,:,:,0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to obtain the next batch based on the input size and the batch size\n",
    "def next_batch(indices, i):\n",
    "    \n",
    "    ind0, ind1 = i*batch_size, np.minimum((i+1)*batch_size, samples)\n",
    "            \n",
    "    return input_metrics[indices[ind0:ind1], :, :, :], output_metric[indices[ind0:ind1], :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building a simple CNN model that looks like an auto-encoder. This is the section to change for a new model.\n",
    "\n",
    "def conv_net(x):\n",
    "    \n",
    "    x = tf.reshape(x, shape=[-1, xdim, ydim, in_chan], name='reshape_x');\n",
    "    x = tf.cast(x, tf.float32) \n",
    "    \n",
    "    # Encoder\n",
    "    # Scale down by 2x2. Out Channels = 32\n",
    "    conv1 = tf.nn.relu(tf.contrib.layers.conv2d(x, 32, [8, 8], stride=2, padding='SAME', \n",
    "                                                biases_initializer=tf.zeros_initializer()))\n",
    "    # Scale down by 2x2. Out Channels = 16\n",
    "    conv2 = tf.nn.relu(tf.contrib.layers.conv2d(conv1, 16, [8, 8], stride=2, padding='SAME', \n",
    "                                                biases_initializer=tf.zeros_initializer()))\n",
    "    # Scale down by 2x2. Out Channels = 8\n",
    "    conv3 = tf.nn.relu(tf.contrib.layers.conv2d(conv2, 8, [8, 8], stride=2, padding='SAME', \n",
    "                                                biases_initializer=tf.zeros_initializer()))\n",
    "    \n",
    "    # Decoder\n",
    "    # Scale up by 2x2. Out Channels = 16\n",
    "    conv4 = tf.nn.relu(tf.contrib.layers.conv2d_transpose(conv3, 16, [8, 8], stride=2, padding='SAME',\n",
    "                                                         biases_initializer=tf.zeros_initializer()))\n",
    "    # Scale up by 2x2. Out Channels = 32\n",
    "    conv5 = tf.nn.relu(tf.contrib.layers.conv2d_transpose(conv4, 32, [8, 8], stride=2, padding='SAME',\n",
    "                                                         biases_initializer=tf.zeros_initializer()))\n",
    "    # Scale up by 2x2. Out Channels = 1\n",
    "    conv6 = tf.nn.relu(tf.contrib.layers.conv2d_transpose(conv5, out_chan, [8, 8], stride=2, padding='SAME',\n",
    "                                                         biases_initializer=tf.zeros_initializer()))\n",
    "    \n",
    "    return conv6;\n",
    "\n",
    "Y = tf.placeholder(tf.float32, shape=(None,xdim,ydim,out_chan));\n",
    "X = tf.placeholder(tf.float32, shape=[None,xdim,ydim,in_chan]);\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001);\n",
    "\n",
    "out = conv_net(X);\n",
    "loss_op = tf.reduce_sum(tf.multiply(Y-out,Y-out));\n",
    "train_op = optimizer.minimize(loss_op);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0 1104.1406161\n",
      "1 992.613292694\n",
      "2 963.476533254\n",
      "3 896.882708867\n",
      "4 858.110800425\n",
      "5 836.51279513\n",
      "6 822.502759933\n",
      "7 815.535288493\n",
      "8 810.30205663\n",
      "9 798.202236176\n",
      "10 795.988983154\n",
      "11 796.320659637\n",
      "12 784.355153402\n",
      "13 780.578964233\n",
      "14 773.817652384\n",
      "15 767.65655454\n",
      "16 762.880091985\n",
      "17 765.170710882\n",
      "18 763.368068695\n",
      "19 759.173635483\n",
      "20 753.837003708\n",
      "21 750.426827749\n",
      "22 747.753831863\n",
      "23 743.867211024\n",
      "24 741.519345601\n",
      "25 739.848567963\n",
      "26 736.294485728\n",
      "27 734.93744278\n",
      "28 739.295982361\n",
      "29 734.517702738\n",
      "30 746.778478622\n",
      "31 737.499676387\n",
      "32 741.798293432\n",
      "33 735.20387586\n",
      "34 728.17932574\n",
      "35 725.868217468\n",
      "36 727.015832265\n",
      "37 726.189908346\n",
      "38 721.746503194\n",
      "39 719.592126211\n",
      "40 716.827125549\n",
      "41 714.216209412\n",
      "42 715.06918335\n",
      "43 714.249135335\n",
      "44 713.811274211\n",
      "45 719.670748393\n",
      "46 707.069187164\n",
      "47 702.964064916\n",
      "48 703.750979741\n",
      "49 700.27777799\n",
      "50 699.88539505\n",
      "51 692.908416748\n",
      "52 691.464989344\n",
      "53 691.045251211\n",
      "54 692.434778214\n",
      "55 694.218255361\n",
      "56 683.545743306\n",
      "57 681.727420171\n",
      "58 680.947147369\n",
      "59 682.984815598\n",
      "60 671.118494034\n",
      "61 667.536135356\n",
      "62 668.029402415\n",
      "63 660.419508616\n",
      "64 657.59327062\n",
      "65 657.407140096\n",
      "66 646.483039856\n",
      "67 643.276428223\n",
      "68 641.035253525\n",
      "69 648.993558248\n",
      "70 653.564751943\n",
      "71 642.681856791\n",
      "72 632.867788951\n",
      "73 625.887913386\n",
      "74 621.726219177\n",
      "75 613.616157532\n",
      "76 610.247545242\n",
      "77 613.509133657\n",
      "78 605.396958669\n",
      "79 605.559583028\n",
      "80 609.370933533\n",
      "81 602.393530528\n",
      "82 598.209758123\n",
      "83 595.153013865\n",
      "84 600.583321253\n",
      "85 587.796496073\n",
      "86 582.154753367\n",
      "87 591.246436437\n",
      "88 592.760623296\n",
      "89 579.379597346\n",
      "90 575.458552678\n",
      "91 601.045142492\n",
      "92 573.973795573\n",
      "93 564.275958379\n",
      "94 560.077849706\n",
      "95 557.650159836\n",
      "96 565.238566081\n",
      "97 558.950389862\n",
      "98 558.674934387\n",
      "99 553.312194824\n",
      "100 579.531110128\n",
      "101 628.392528534\n",
      "102 581.331544876\n",
      "103 560.194212596\n",
      "104 555.741523107\n",
      "105 545.586510976\n",
      "106 539.250535329\n",
      "107 534.151148478\n",
      "108 536.70781072\n",
      "109 542.075719833\n",
      "110 548.086843491\n",
      "111 535.944957733\n",
      "112 533.267052968\n",
      "113 530.492646535\n",
      "114 546.603687286\n",
      "115 533.145769755\n",
      "116 520.115745544\n",
      "117 519.016362508\n",
      "118 514.163554509\n",
      "119 515.074763934\n",
      "120 523.569627762\n",
      "121 526.062253316\n",
      "122 512.94141833\n",
      "123 512.602121989\n",
      "124 510.268802961\n",
      "125 555.240011851\n",
      "126 536.361441294\n",
      "127 509.219889959\n",
      "128 502.126716614\n",
      "129 498.311126073\n",
      "130 495.756182353\n",
      "131 503.591563543\n",
      "132 497.075957934\n",
      "133 493.412849426\n",
      "134 495.291432063\n",
      "135 504.081943512\n",
      "136 492.065162023\n",
      "137 485.803510666\n",
      "138 491.917768478\n",
      "139 489.857024511\n",
      "140 481.927982966\n",
      "141 481.990596135\n",
      "142 510.780872663\n",
      "143 492.263580322\n",
      "144 485.838727315\n",
      "145 480.221334457\n",
      "146 473.669195175\n",
      "147 470.110865911\n",
      "148 470.217954636\n",
      "149 467.234853109\n",
      "150 467.354908307\n",
      "151 464.457859675\n",
      "152 469.12760512\n",
      "153 464.212279638\n",
      "154 461.570291519\n",
      "155 460.125150363\n",
      "156 464.1890227\n",
      "157 463.884312312\n",
      "158 464.316870054\n",
      "159 464.995312055\n",
      "160 463.654875437\n",
      "161 459.789487203\n",
      "162 498.849051793\n",
      "163 471.288832347\n",
      "164 464.364098867\n",
      "165 457.006728808\n",
      "166 461.139489174\n",
      "167 455.925703049\n",
      "168 452.225999514\n",
      "169 448.02589798\n",
      "170 446.218908946\n",
      "171 445.269457181\n",
      "172 444.576061567\n",
      "173 442.872086843\n",
      "174 472.099572817\n",
      "175 517.863291423\n",
      "176 495.022539775\n",
      "177 457.913845062\n",
      "178 448.196853638\n",
      "179 440.066337585\n",
      "180 453.794960658\n",
      "181 442.012380918\n",
      "182 438.380576452\n",
      "183 434.444469134\n",
      "184 433.154132843\n",
      "185 437.923118909\n",
      "186 434.127605438\n",
      "187 429.874026299\n",
      "188 425.121756236\n",
      "189 429.854192734\n",
      "190 423.530884425\n",
      "191 429.190382957\n",
      "192 427.972837766\n",
      "193 440.45648543\n",
      "194 441.885391871\n",
      "195 429.777349472\n",
      "196 427.340174357\n",
      "197 425.894191106\n",
      "198 420.185982068\n",
      "199 427.183675448\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200;\n",
    "batch_size = 8;\n",
    "num_batches = int(np.ceil(float(samples) / batch_size));\n",
    "print(num_batches)\n",
    "\n",
    "loss_arr = [];\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run the initializer\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        indices = np.random.permutation(samples);\n",
    "        \n",
    "        # Compute the loss across all the batches\n",
    "        total_loss = 0;\n",
    "        for i in range(num_batches):\n",
    "            x_train, y_train = next_batch(indices, i);\n",
    "            [loss, train] = sess.run([loss_op, train_op], feed_dict={X: x_train, Y: y_train});            \n",
    "            total_loss += loss;\n",
    "        \n",
    "        loss_arr.append(total_loss / num_batches);\n",
    "        print(epoch, total_loss / num_batches);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_arr);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
